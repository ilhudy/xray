"""
============================================
ğŸš€ X-Ray Segmentation ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
============================================
í•™ìŠµ ë° ì¶”ë¡ ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    # í•™ìŠµ
    python main.py --config configs/exp01_fcn_resnet50.yaml --mode train
    
    # ì¶”ë¡ 
    python main.py --config configs/exp01_fcn_resnet50.yaml --mode inference
    
    # í•™ìŠµ + ì¶”ë¡ 
    python main.py --config configs/exp01_fcn_resnet50.yaml --mode all
"""

import argparse
import datetime
import os

import albumentations as A
import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
import torch.optim as optim
import yaml
from torch.utils.data import DataLoader
from tqdm import tqdm

from src.dataset import XRayDataset, XRayInferenceDataset
from src.losses import get_loss
from src.models import get_model
from src.utils import (
    dice_coef,
    encode_mask_to_rle,
    get_device,
    print_model_info,
    save_model,
    set_seed,
)


def load_config(config_path: str) -> dict:
    """YAML ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    print(f"ğŸ“„ Config loaded from {config_path}")
    return config


def get_transforms(config: dict, is_train: bool = True):
    """Augmentation ë³€í™˜ ìƒì„±"""
    aug_config = config["augmentation"]["train" if is_train else "valid"]
    
    transforms_list = []
    
    # Resize (í•„ìˆ˜)
    transforms_list.append(A.Resize(aug_config["resize"], aug_config["resize"]))
    
    # í•™ìŠµì‹œ ì¶”ê°€ augmentation
    if is_train:
        if aug_config.get("horizontal_flip", False):
            transforms_list.append(A.HorizontalFlip(p=0.5))
        
        if aug_config.get("vertical_flip", False):
            transforms_list.append(A.VerticalFlip(p=0.5))
        
        if aug_config.get("rotate", False):
            limit = aug_config.get("rotate_limit", 15)
            transforms_list.append(A.Rotate(limit=limit, p=0.5))
        
        if aug_config.get("brightness_contrast", False):
            transforms_list.append(A.RandomBrightnessContrast(p=0.3))
        
        if aug_config.get("elastic_transform", False):
            transforms_list.append(A.ElasticTransform(p=0.3))
        
        if aug_config.get("grid_distortion", False):
            transforms_list.append(A.GridDistortion(p=0.3))
    
    return A.Compose(transforms_list)


def get_optimizer(model, config: dict):
    """ì˜µí‹°ë§ˆì´ì € ìƒì„±"""
    opt_name = config["training"].get("optimizer", "adam").lower()
    lr = config["training"]["learning_rate"]
    weight_decay = config["training"].get("weight_decay", 1e-6)
    
    if opt_name == "adam":
        return optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    elif opt_name == "adamw":
        return optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    elif opt_name == "sgd":
        return optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)
    else:
        raise ValueError(f"Unknown optimizer: {opt_name}")


def get_scheduler(optimizer, config: dict):
    """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±"""
    scheduler_name = config["training"].get("scheduler")
    
    if scheduler_name is None:
        return None
    elif scheduler_name == "cosine":
        return optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=config["training"]["epochs"]
        )
    elif scheduler_name == "step":
        return optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
    else:
        raise ValueError(f"Unknown scheduler: {scheduler_name}")


def validation(epoch, model, data_loader, criterion, classes, device, thr=0.5):
    """ê²€ì¦ ìˆ˜í–‰"""
    print(f"\nğŸ” Validation #{epoch}")
    model.eval()
    
    dices = []
    total_loss = 0
    cnt = 0
    
    with torch.no_grad():
        for images, masks in tqdm(data_loader, desc="Validating"):
            images, masks = images.to(device), masks.to(device)
            
            outputs = model(images)["out"]
            
            # í¬ê¸° ë§ì¶”ê¸°
            output_h, output_w = outputs.size(-2), outputs.size(-1)
            mask_h, mask_w = masks.size(-2), masks.size(-1)
            
            if output_h != mask_h or output_w != mask_w:
                outputs = F.interpolate(outputs, size=(mask_h, mask_w), mode="bilinear")
            
            loss = criterion(outputs, masks)
            total_loss += loss.item()
            cnt += 1
            
            outputs = torch.sigmoid(outputs)
            outputs = (outputs > thr).float()
            
            dice = dice_coef(outputs, masks)
            dices.append(dice.cpu())
    
    dices = torch.cat(dices, 0)
    dices_per_class = torch.mean(dices, 0)
    
    # í´ë˜ìŠ¤ë³„ Dice ì¶œë ¥
    print("\nğŸ“Š Class-wise Dice Scores:")
    for c, d in zip(classes, dices_per_class):
        print(f"  {c:<15}: {d.item():.4f}")
    
    avg_dice = torch.mean(dices_per_class).item()
    avg_loss = total_loss / cnt
    
    print(f"\nğŸ“ˆ Average Dice: {avg_dice:.4f}")
    print(f"ğŸ“‰ Average Loss: {avg_loss:.4f}")
    
    return avg_dice


def train(config: dict, device: str):
    """í•™ìŠµ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ğŸ“ TRAINING START")
    print("=" * 60)
    
    # ì„¤ì • ì¶”ì¶œ
    classes = config["classes"]
    num_classes = len(classes)
    
    # Transform ìƒì„±
    train_transform = get_transforms(config, is_train=True)
    valid_transform = get_transforms(config, is_train=False)
    
    # Dataset ìƒì„±
    train_dataset = XRayDataset(
        image_root=config["data"]["train_image_root"],
        label_root=config["data"]["train_label_root"],
        classes=classes,
        is_train=True,
        transforms=train_transform,
        n_splits=config["training"]["n_splits"],
        fold=config["training"]["fold"],
    )
    
    valid_dataset = XRayDataset(
        image_root=config["data"]["train_image_root"],
        label_root=config["data"]["train_label_root"],
        classes=classes,
        is_train=False,
        transforms=valid_transform,
        n_splits=config["training"]["n_splits"],
        fold=config["training"]["fold"],
    )
    
    # DataLoader ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=config["training"]["batch_size"],
        shuffle=True,
        num_workers=config["training"]["num_workers"],
        drop_last=True,
    )
    
    valid_loader = DataLoader(
        valid_dataset,
        batch_size=config["training"]["batch_size"],
        shuffle=False,
        num_workers=0,
        drop_last=False,
    )
    
    # ëª¨ë¸ ìƒì„±
    model = get_model(
        config["model"]["name"],
        num_classes=num_classes,
        pretrained=config["model"]["pretrained"],
    )
    model = model.to(device)
    print_model_info(model, config["model"]["name"])
    
    # Loss, Optimizer, Scheduler ì„¤ì •
    loss_config = config.get("loss", {})
    loss_name = loss_config.get("name", "bce")
    loss_kwargs = {k: v for k, v in loss_config.items() if k != "name"}
    criterion = get_loss(loss_name, **loss_kwargs)
    
    optimizer = get_optimizer(model, config)
    scheduler = get_scheduler(optimizer, config)
    
    print(f"\nğŸ“Œ Loss: {loss_name}")
    print(f"ğŸ“Œ Optimizer: {config['training'].get('optimizer', 'adam')}")
    print(f"ğŸ“Œ Scheduler: {config['training'].get('scheduler', 'None')}")
    
    # í•™ìŠµ ë£¨í”„
    best_dice = 0.0
    epochs = config["training"]["epochs"]
    val_every = config["training"]["val_every"]
    
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{epochs}")
        for step, (images, masks) in enumerate(pbar):
            images, masks = images.to(device), masks.to(device)
            
            outputs = model(images)["out"]
            loss = criterion(outputs, masks)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})
        
        if scheduler is not None:
            scheduler.step()
        
        avg_epoch_loss = epoch_loss / len(train_loader)
        print(f"\nğŸ“Š Epoch {epoch + 1} - Average Loss: {avg_epoch_loss:.4f}")
        
        # ê²€ì¦
        if (epoch + 1) % val_every == 0:
            dice = validation(
                epoch + 1, model, valid_loader, criterion, classes, device
            )
            
            if dice > best_dice:
                print(f"\nğŸ‰ Best Dice improved: {best_dice:.4f} â†’ {dice:.4f}")
                best_dice = dice
                save_model(
                    model,
                    config["save"]["dir"],
                    config["save"]["model_name"],
                )
    
    print("\n" + "=" * 60)
    print(f"ğŸ† Training Complete! Best Dice: {best_dice:.4f}")
    print("=" * 60)


def inference(config: dict, device: str):
    """ì¶”ë¡  ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ğŸ”® INFERENCE START")
    print("=" * 60)
    
    classes = config["classes"]
    num_classes = len(classes)
    ind2class = {i: v for i, v in enumerate(classes)}
    
    # Transform ìƒì„±
    test_transform = get_transforms(config, is_train=False)
    
    # Dataset ìƒì„±
    test_dataset = XRayInferenceDataset(
        image_root=config["data"]["test_image_root"],
        transforms=test_transform,
    )
    
    # DataLoader ìƒì„±
    test_loader = DataLoader(
        test_dataset,
        batch_size=config["inference"]["batch_size"],
        shuffle=False,
        num_workers=2,
        drop_last=False,
    )
    
    # ëª¨ë¸ ë¡œë“œ
    model = get_model(
        config["model"]["name"],
        num_classes=num_classes,
        pretrained=False,
    )
    
    model_path = os.path.join(config["save"]["dir"], config["save"]["model_name"])
    model.load_state_dict(torch.load(model_path, map_location=device))
    model = model.to(device)
    model.eval()
    
    print(f"ğŸ“‚ Model loaded from {model_path}")
    
    # ì¶”ë¡ 
    rles = []
    filename_and_class = []
    thr = config["inference"]["threshold"]
    original_size = config["image"]["original_size"]
    
    with torch.no_grad():
        for images, image_names in tqdm(test_loader, desc="Inferencing"):
            images = images.to(device)
            outputs = model(images)["out"]
            
            outputs = F.interpolate(
                outputs, size=(original_size, original_size), mode="bilinear"
            )
            outputs = torch.sigmoid(outputs)
            outputs = (outputs > thr).detach().cpu().numpy()
            
            for output, image_name in zip(outputs, image_names):
                for c, segm in enumerate(output):
                    rle = encode_mask_to_rle(segm)
                    rles.append(rle)
                    filename_and_class.append(f"{ind2class[c]}_{image_name}")
    
    # CSV ì €ì¥
    classes_list, filename_list = zip(
        *[x.split("_", 1) for x in filename_and_class]
    )
    image_names = [os.path.basename(f) for f in filename_list]
    
    df = pd.DataFrame({
        "image_name": image_names,
        "class": classes_list,
        "rle": rles,
    })
    
    output_csv = config["inference"]["output_csv"]
    df.to_csv(output_csv, index=False)
    
    print(f"\nğŸ’¾ Results saved to {output_csv}")
    print(f"ğŸ“Š Total predictions: {len(df)}")
    
    print("\n" + "=" * 60)
    print("ğŸ† Inference Complete!")
    print("=" * 60)


def main():
    parser = argparse.ArgumentParser(description="X-Ray Segmentation Training/Inference")
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Path to config yaml file",
    )
    parser.add_argument(
        "--mode",
        type=str,
        choices=["train", "inference", "all"],
        default="train",
        help="Execution mode: train, inference, or all",
    )
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = load_config(args.config)
    
    # ì‹œë“œ ì„¤ì •
    set_seed(config.get("seed", 42))
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = get_device()
    
    # ì‹¤í—˜ ì •ë³´ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“‹ EXPERIMENT INFO")
    print("=" * 60)
    print(f"Name: {config['experiment']['name']}")
    print(f"Description: {config['experiment']['description']}")
    print(f"Author: {config['experiment']['author']}")
    print(f"Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # ì‹¤í–‰
    if args.mode in ["train", "all"]:
        train(config, device)
    
    if args.mode in ["inference", "all"]:
        inference(config, device)


if __name__ == "__main__":
    main()

