"""
============================================
ğŸ”® X-Ray Segmentation ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
============================================
í•™ìŠµëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ë¡  í›„ CSV íŒŒì¼ ìƒì„±

ì‚¬ìš©ë²•:
    # Config íŒŒì¼ ì‚¬ìš©
    python inference.py --config configs/exp01_fcn_resnet50.yaml
    
    # ì§ì ‘ ëª¨ë¸ ê²½ë¡œ ì§€ì •
    python inference.py --model saved_models/exp01/best_model.pt --output output.csv
    
    # ëª¨ë¸ ì´ë¦„ê³¼ ê²½ë¡œ ì§ì ‘ ì§€ì •
    python inference.py --model saved_models/exp01/best_model.pt \
                        --model_name fcn_resnet50 \
                        --output my_submission.csv
"""

import argparse
import os

import albumentations as A
import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
import yaml
from torch.utils.data import DataLoader
from tqdm import tqdm

from src.dataset import XRayInferenceDataset
from src.models import get_model
from src.utils import encode_mask_to_rle, set_seed

# ê¸°ë³¸ í´ë˜ìŠ¤ ëª©ë¡
CLASSES = [
    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',
    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',
    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',
    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',
    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',
    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',
]

IND2CLASS = {i: v for i, v in enumerate(CLASSES)}


def inference(
    model_path: str,
    test_image_root: str,
    output_csv: str,
    model_name: str = "fcn_resnet50",
    image_size: int = 512,
    original_size: int = 2048,
    batch_size: int = 2,
    threshold: float = 0.5,
    device: str = None,
):
    """
    ì¶”ë¡  ì‹¤í–‰ ë° CSV ìƒì„±
    
    Args:
        model_path: í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pt)
        test_image_root: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        output_csv: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ
        model_name: ëª¨ë¸ ì´ë¦„ (fcn_resnet50, deeplabv3_resnet101 ë“±)
        image_size: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
        original_size: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (ì¶œë ¥ í¬ê¸°)
        batch_size: ë°°ì¹˜ í¬ê¸°
        threshold: ì´ì§„í™” ì„ê³„ê°’
        device: ë””ë°”ì´ìŠ¤ (Noneì´ë©´ ìë™ ì„ íƒ)
    """
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ Using device: {device}")
    
    # Transform
    transform = A.Resize(image_size, image_size)
    
    # Dataset & DataLoader
    test_dataset = XRayInferenceDataset(
        image_root=test_image_root,
        transforms=transform,
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,
        drop_last=False,
    )
    
    # ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ“‚ Loading model from {model_path}")
    model = get_model(model_name, num_classes=len(CLASSES), pretrained=False)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model = model.to(device)
    model.eval()
    
    print(f"âœ… Model loaded successfully!")
    print(f"ğŸ“Š Test samples: {len(test_dataset)}")
    
    # ì¶”ë¡ 
    rles = []
    filename_and_class = []
    
    print("\nğŸ”® Starting inference...")
    with torch.no_grad():
        for images, image_names in tqdm(test_loader, desc="Inferencing"):
            images = images.to(device)
            outputs = model(images)["out"]
            
            # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
            outputs = F.interpolate(
                outputs, size=(original_size, original_size), mode="bilinear"
            )
            outputs = torch.sigmoid(outputs)
            outputs = (outputs > threshold).detach().cpu().numpy()
            
            for output, image_name in zip(outputs, image_names):
                for c, segm in enumerate(output):
                    rle = encode_mask_to_rle(segm)
                    rles.append(rle)
                    filename_and_class.append(f"{IND2CLASS[c]}_{image_name}")
    
    # CSV ìƒì„±
    classes_list, filename_list = zip(
        *[x.split("_", 1) for x in filename_and_class]
    )
    image_names = [os.path.basename(f) for f in filename_list]
    
    df = pd.DataFrame({
        "image_name": image_names,
        "class": classes_list,
        "rle": rles,
    })
    
    df.to_csv(output_csv, index=False)
    
    print(f"\n{'='*60}")
    print(f"ğŸ‰ Inference Complete!")
    print(f"{'='*60}")
    print(f"ğŸ“ Output CSV: {output_csv}")
    print(f"ğŸ“Š Total predictions: {len(df)}")
    print(f"ğŸ–¼ï¸ Total images: {len(df) // len(CLASSES)}")
    print(f"{'='*60}")
    
    return df


def main():
    parser = argparse.ArgumentParser(
        description="X-Ray Segmentation Inference & CSV Generation"
    )
    
    # Config íŒŒì¼ ì‚¬ìš©
    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help="Config yaml file path (ì„ íƒì‚¬í•­)",
    )
    
    # ì§ì ‘ ì§€ì •
    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pt)",
    )
    parser.add_argument(
        "--model_name",
        type=str,
        default="fcn_resnet50",
        help="ëª¨ë¸ ì´ë¦„ (fcn_resnet50, deeplabv3_resnet101 ë“±)",
    )
    parser.add_argument(
        "--test_root",
        type=str,
        default="data/test/DCM",
        help="í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="output.csv",
        help="ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ",
    )
    parser.add_argument(
        "--image_size",
        type=int,
        default=512,
        help="ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°",
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.5,
        help="ì´ì§„í™” ì„ê³„ê°’",
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=2,
        help="ë°°ì¹˜ í¬ê¸°",
    )
    
    args = parser.parse_args()
    
    # Config íŒŒì¼ ì‚¬ìš©
    if args.config:
        print(f"ğŸ“„ Loading config from {args.config}")
        with open(args.config, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        
        model_path = os.path.join(
            config["save"]["dir"], 
            config["save"]["model_name"]
        )
        
        inference(
            model_path=model_path,
            test_image_root=config["data"]["test_image_root"],
            output_csv=config["inference"]["output_csv"],
            model_name=config["model"]["name"],
            image_size=config["image"]["size"],
            original_size=config["image"]["original_size"],
            batch_size=config["inference"]["batch_size"],
            threshold=config["inference"]["threshold"],
        )
    
    # ì§ì ‘ ì§€ì •
    elif args.model:
        inference(
            model_path=args.model,
            test_image_root=args.test_root,
            output_csv=args.output,
            model_name=args.model_name,
            image_size=args.image_size,
            batch_size=args.batch_size,
            threshold=args.threshold,
        )
    
    else:
        print("âŒ Error: --config ë˜ëŠ” --model ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
        print("\nì‚¬ìš© ì˜ˆì‹œ:")
        print("  python inference.py --config configs/exp01_fcn_resnet50.yaml")
        print("  python inference.py --model saved_models/exp01/best_model.pt --output output.csv")
        parser.print_help()


if __name__ == "__main__":
    main()

