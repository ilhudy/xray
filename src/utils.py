"""
============================================
ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
============================================
í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ëª¨ìŒ
"""

import os
import random
import numpy as np
import torch


# ============================================
# ğŸ² ì‹œë“œ ê³ ì •
# ============================================

def set_seed(seed: int = 42):
    """
    ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
    
    Args:
        seed (int): ì‹œë“œ ê°’
    """
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    np.random.seed(seed)
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    print(f"ğŸ² Seed set to {seed}")


# ============================================
# ğŸ’¾ ëª¨ë¸ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
# ============================================

def save_model(model, save_dir: str, file_name: str = "best_model.pt"):
    """
    ëª¨ë¸ ì €ì¥
    
    Args:
        model: ì €ì¥í•  ëª¨ë¸
        save_dir (str): ì €ì¥ ë””ë ‰í† ë¦¬
        file_name (str): íŒŒì¼ ì´ë¦„
    """
    os.makedirs(save_dir, exist_ok=True)
    output_path = os.path.join(save_dir, file_name)
    torch.save(model.state_dict(), output_path)
    print(f"ğŸ’¾ Model saved to {output_path}")


def load_model(model, model_path: str, device: str = "cuda"):
    """
    ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    
    Args:
        model: ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        model_path (str): ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
        device (str): ë””ë°”ì´ìŠ¤
    
    Returns:
        ë¶ˆëŸ¬ì˜¨ ëª¨ë¸
    """
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    print(f"ğŸ“‚ Model loaded from {model_path}")
    return model


# ============================================
# ğŸ“Š í‰ê°€ ì§€í‘œ
# ============================================

def dice_coef(y_true: torch.Tensor, y_pred: torch.Tensor, eps: float = 1e-4) -> torch.Tensor:
    """
    Dice Coefficient ê³„ì‚°
    
    Args:
        y_true: ì •ë‹µ ë§ˆìŠ¤í¬
        y_pred: ì˜ˆì¸¡ ë§ˆìŠ¤í¬
        eps: ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€
    
    Returns:
        í´ë˜ìŠ¤ë³„ Dice coefficient (shape: [batch_size, num_classes])
    """
    y_true_f = y_true.flatten(2)
    y_pred_f = y_pred.flatten(2)
    
    intersection = torch.sum(y_true_f * y_pred_f, -1)
    return (2.0 * intersection + eps) / (torch.sum(y_true_f, -1) + torch.sum(y_pred_f, -1) + eps)


# ============================================
# ğŸ”„ RLE ì¸ì½”ë”©/ë””ì½”ë”©
# ============================================

def encode_mask_to_rle(mask: np.ndarray) -> str:
    """
    ë§ˆìŠ¤í¬ë¥¼ RLE(Run-Length Encoding)ë¡œ ì¸ì½”ë”©
    
    Args:
        mask: ì´ì§„ ë§ˆìŠ¤í¬ (numpy array)
    
    Returns:
        RLE ë¬¸ìì—´
    """
    pixels = mask.flatten()
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return " ".join(str(x) for x in runs)


def decode_rle_to_mask(rle: str, height: int, width: int) -> np.ndarray:
    """
    RLEë¥¼ ë§ˆìŠ¤í¬ë¡œ ë””ì½”ë”©
    
    Args:
        rle: RLE ë¬¸ìì—´
        height: ì´ë¯¸ì§€ ë†’ì´
        width: ì´ë¯¸ì§€ ë„ˆë¹„
    
    Returns:
        ì´ì§„ ë§ˆìŠ¤í¬ (numpy array)
    """
    s = rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]
    starts -= 1
    ends = starts + lengths
    
    img = np.zeros(height * width, dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    
    return img.reshape(height, width)


# ============================================
# ğŸ¨ ì‹œê°í™”
# ============================================

# 29ê°œ í´ë˜ìŠ¤ìš© ìƒ‰ìƒ íŒ”ë ˆíŠ¸
PALETTE = [
    (220, 20, 60), (119, 11, 32), (0, 0, 142), (0, 0, 230), (106, 0, 228),
    (0, 60, 100), (0, 80, 100), (0, 0, 70), (0, 0, 192), (250, 170, 30),
    (100, 170, 30), (220, 220, 0), (175, 116, 175), (250, 0, 30), (165, 42, 42),
    (255, 77, 255), (0, 226, 252), (182, 182, 255), (0, 82, 0), (120, 166, 157),
    (110, 76, 0), (174, 57, 255), (199, 100, 0), (72, 0, 118), (255, 179, 240),
    (0, 125, 92), (209, 0, 151), (188, 208, 182), (0, 220, 176),
]


def label2rgb(label: np.ndarray, palette: list = None) -> np.ndarray:
    """
    ë¼ë²¨ ë§ˆìŠ¤í¬ë¥¼ RGB ì´ë¯¸ì§€ë¡œ ë³€í™˜
    
    Args:
        label: ë¼ë²¨ ë§ˆìŠ¤í¬ (shape: [num_classes, H, W])
        palette: ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (ê¸°ë³¸ê°’: PALETTE)
    
    Returns:
        RGB ì´ë¯¸ì§€ (shape: [H, W, 3])
    """
    if palette is None:
        palette = PALETTE
    
    image_size = label.shape[1:] + (3,)
    image = np.zeros(image_size, dtype=np.uint8)
    
    for i, class_label in enumerate(label):
        image[class_label == 1] = palette[i % len(palette)]
    
    return image


# ============================================
# ğŸ“‹ ê¸°íƒ€ ìœ í‹¸ë¦¬í‹°
# ============================================

def get_device():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸ Using device: {device}")
    if device == "cuda":
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
    return device


def count_parameters(model) -> int:
    """ëª¨ë¸ì˜ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ë°˜í™˜"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


def print_model_info(model, model_name: str = "Model"):
    """ëª¨ë¸ ì •ë³´ ì¶œë ¥"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = count_parameters(model)
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š {model_name} Info")
    print(f"{'='*50}")
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    print(f"Non-trainable parameters: {total_params - trainable_params:,}")
    print(f"{'='*50}\n")

