"""
============================================
ğŸ“‰ Loss í•¨ìˆ˜ ì •ì˜
============================================
Segmentation í•™ìŠµì„ ìœ„í•œ ë‹¤ì–‘í•œ Loss í•¨ìˆ˜
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class DiceLoss(nn.Module):
    """
    Dice Loss
    
    Segmentationì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” lossë¡œ, 
    ì˜ˆì¸¡ê³¼ ì •ë‹µì˜ ê²¹ì¹˜ëŠ” ì˜ì—­ì„ ìµœëŒ€í™”
    
    Args:
        smooth (float): ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€
    """
    
    def __init__(self, smooth: float = 1e-6):
        super().__init__()
        self.smooth = smooth
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        pred = torch.sigmoid(pred)
        
        pred_flat = pred.flatten(2)
        target_flat = target.flatten(2)
        
        intersection = (pred_flat * target_flat).sum(-1)
        union = pred_flat.sum(-1) + target_flat.sum(-1)
        
        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)
        return 1.0 - dice.mean()


class BCEDiceLoss(nn.Module):
    """
    BCE + Dice Loss ì¡°í•©
    
    BCEëŠ” í”½ì…€ ë‹¨ìœ„ í•™ìŠµ, DiceëŠ” ì˜ì—­ ë‹¨ìœ„ í•™ìŠµì— íš¨ê³¼ì 
    ë‘ lossë¥¼ ì¡°í•©í•˜ì—¬ ë” ì•ˆì •ì ì¸ í•™ìŠµ ê°€ëŠ¥
    
    Args:
        bce_weight (float): BCE loss ê°€ì¤‘ì¹˜
        dice_weight (float): Dice loss ê°€ì¤‘ì¹˜
    """
    
    def __init__(self, bce_weight: float = 0.5, dice_weight: float = 0.5):
        super().__init__()
        self.bce_weight = bce_weight
        self.dice_weight = dice_weight
        self.bce = nn.BCEWithLogitsLoss()
        self.dice = DiceLoss()
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        bce_loss = self.bce(pred, target)
        dice_loss = self.dice(pred, target)
        return self.bce_weight * bce_loss + self.dice_weight * dice_loss


class FocalLoss(nn.Module):
    """
    Focal Loss
    
    í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°ì— íš¨ê³¼ì 
    ì‰¬ìš´ ìƒ˜í”Œì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¤„ì´ê³  ì–´ë ¤ìš´ ìƒ˜í”Œì— ì§‘ì¤‘
    
    Args:
        alpha (float): ì–‘ì„± í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜
        gamma (float): focusing parameter (í´ìˆ˜ë¡ ì–´ë ¤ìš´ ìƒ˜í”Œì— ì§‘ì¤‘)
    """
    
    def __init__(self, alpha: float = 0.25, gamma: float = 2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        bce = F.binary_cross_entropy_with_logits(pred, target, reduction='none')
        pt = torch.exp(-bce)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce
        return focal_loss.mean()


class TverskyLoss(nn.Module):
    """
    Tversky Loss
    
    Dice Lossì˜ ì¼ë°˜í™” ë²„ì „
    False Positiveì™€ False Negativeì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì ˆ ê°€ëŠ¥
    
    Args:
        alpha (float): False Positive ê°€ì¤‘ì¹˜
        beta (float): False Negative ê°€ì¤‘ì¹˜
        smooth (float): ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€
    """
    
    def __init__(self, alpha: float = 0.5, beta: float = 0.5, smooth: float = 1e-6):
        super().__init__()
        self.alpha = alpha
        self.beta = beta
        self.smooth = smooth
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        pred = torch.sigmoid(pred)
        
        pred_flat = pred.flatten(2)
        target_flat = target.flatten(2)
        
        tp = (pred_flat * target_flat).sum(-1)
        fp = (pred_flat * (1 - target_flat)).sum(-1)
        fn = ((1 - pred_flat) * target_flat).sum(-1)
        
        tversky = (tp + self.smooth) / (tp + self.alpha * fp + self.beta * fn + self.smooth)
        return 1.0 - tversky.mean()


class CombinedLoss(nn.Module):
    """
    ì—¬ëŸ¬ Lossì˜ ì¡°í•©
    
    ë‹¤ì–‘í•œ lossë¥¼ ê°€ì¤‘ì¹˜ì™€ í•¨ê»˜ ì¡°í•©í•˜ì—¬ ì‚¬ìš©
    
    Args:
        losses (list): (loss_fn, weight) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
    
    Example:
        >>> loss_fn = CombinedLoss([
        ...     (nn.BCEWithLogitsLoss(), 0.5),
        ...     (DiceLoss(), 0.3),
        ...     (FocalLoss(), 0.2),
        ... ])
    """
    
    def __init__(self, losses: list):
        super().__init__()
        self.losses = nn.ModuleList([loss_fn for loss_fn, _ in losses])
        self.weights = [weight for _, weight in losses]
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        total_loss = 0
        for loss_fn, weight in zip(self.losses, self.weights):
            total_loss += weight * loss_fn(pred, target)
        return total_loss


# ============================================
# ğŸ“Œ Loss í•¨ìˆ˜ ì„ íƒ í—¬í¼
# ============================================

def get_loss(loss_name: str, **kwargs) -> nn.Module:
    """
    Loss í•¨ìˆ˜ ì´ë¦„ìœ¼ë¡œ ìƒì„±
    
    Args:
        loss_name (str): Loss í•¨ìˆ˜ ì´ë¦„
            - "bce": BCEWithLogitsLoss
            - "dice": DiceLoss
            - "bce_dice": BCEDiceLoss
            - "focal": FocalLoss
            - "tversky": TverskyLoss
        **kwargs: Loss í•¨ìˆ˜ì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
    
    Returns:
        nn.Module: Loss í•¨ìˆ˜
    
    Example:
        >>> loss_fn = get_loss("bce_dice", bce_weight=0.5, dice_weight=0.5)
    """
    
    loss_name = loss_name.lower()
    
    loss_dict = {
        "bce": nn.BCEWithLogitsLoss,
        "dice": DiceLoss,
        "bce_dice": BCEDiceLoss,
        "focal": FocalLoss,
        "tversky": TverskyLoss,
    }
    
    if loss_name not in loss_dict:
        raise ValueError(
            f"ì§€ì›í•˜ì§€ ì•ŠëŠ” lossì…ë‹ˆë‹¤: {loss_name}\n"
            f"ì§€ì› loss: {list(loss_dict.keys())}"
        )
    
    return loss_dict[loss_name](**kwargs)

